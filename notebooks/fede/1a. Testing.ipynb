{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11a61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "\n",
    "import sys; sys.path.append(\"../../\")\n",
    "from modules.utils import load_yaml, load_pkl, make_directory, save_pkl, save_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1053083",
   "metadata": {},
   "source": [
    "# Read Data\n",
    "\n",
    "Note: in the submission, we cannot use `test.csv`. This has no labels and it is for submission only. So we need to use validation data as the test\n",
    "\n",
    "--> This should be OK since the data size seems large enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec6863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../config/train_config.yaml\n"
     ]
    }
   ],
   "source": [
    "TRAIN_CONFIG_PATH = '../../config/train_config.yaml'\n",
    "DATA_PATH = '../../data/01_split/'\n",
    "\n",
    "config = load_yaml(TRAIN_CONFIG_PATH)\n",
    "LABEL_ENCODING = config['LABEL_ENCODING']\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'valid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee75e53",
   "metadata": {},
   "source": [
    "## Split into train and test\n",
    "\n",
    "As said, we will use val and test as the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4108511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_df.loc[:,train_df.columns!='leaktype'], train_df['leaktype']\n",
    "valid_X, valid_y = valid_df.loc[:,train_df.columns!='leaktype'], valid_df['leaktype']\n",
    "\n",
    "train_y = train_y.replace(LABEL_ENCODING)\n",
    "valid_y = valid_y.replace(LABEL_ENCODING)\n",
    "\n",
    "# Same testing and validation\n",
    "test_X, test_y = valid_X, valid_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1288c9cd",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d78fd92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, max_features=500, max_leaf_nodes=30,\n",
       "                       n_estimators=600, random_state=123)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_features = 500,n_estimators = 600,max_depth = 3,min_samples_split = 2,max_leaf_nodes = 30, random_state=123)\n",
    "rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b8b02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "679aafca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:07:42] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/botu/Dev/aichallenge-2022/notebooks/fede/1a. Testing.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224461727468426f7475227d/home/botu/Dev/aichallenge-2022/notebooks/fede/1a.%20Testing.ipynb#ch0000029vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224461727468426f7475227d/home/botu/Dev/aichallenge-2022/notebooks/fede/1a.%20Testing.ipynb#ch0000029vscode-remote?line=4'>5</a>\u001b[0m xgb \u001b[39m=\u001b[39m xgboost\u001b[39m.\u001b[39mXGBClassifier(verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224461727468426f7475227d/home/botu/Dev/aichallenge-2022/notebooks/fede/1a.%20Testing.ipynb#ch0000029vscode-remote?line=5'>6</a>\u001b[0m xgb\u001b[39m.\u001b[39;49mfit(train_X, train_y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=529'>530</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=530'>531</a>\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=531'>532</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1378'>1379</a>\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1379'>1380</a>\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1380'>1381</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1381'>1382</a>\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1382'>1383</a>\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1383'>1384</a>\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1396'>1397</a>\u001b[0m     enable_categorical\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1397'>1398</a>\u001b[0m )\n\u001b[0;32m-> <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1399'>1400</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1400'>1401</a>\u001b[0m     params,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1401'>1402</a>\u001b[0m     train_dmatrix,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1402'>1403</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1403'>1404</a>\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1404'>1405</a>\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1405'>1406</a>\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1406'>1407</a>\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1407'>1408</a>\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1408'>1409</a>\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1409'>1410</a>\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1410'>1411</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1411'>1412</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1413'>1414</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/sklearn.py?line=1414'>1415</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=529'>530</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=530'>531</a>\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=531'>532</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/training.py?line=178'>179</a>\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/training.py?line=179'>180</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/training.py?line=180'>181</a>\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/training.py?line=181'>182</a>\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/training.py?line=182'>183</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1733\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=1729'>1730</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=1731'>1732</a>\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=1732'>1733</a>\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=1733'>1734</a>\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=1734'>1735</a>\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=1735'>1736</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/botu/.local/lib/python3.10/site-packages/xgboost/core.py?line=1736'>1737</a>\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# XG\n",
    "\n",
    "import xgboost\n",
    "\n",
    "xgb = xgboost.XGBClassifier(verbose=1)\n",
    "xgb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17cb366",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c7ebe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = rf.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ace8ce",
   "metadata": {},
   "source": [
    "# Metrics evaluation\n",
    "\n",
    "We need to get a few metrics right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d1d3558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'other', 1: 'noise', 2: 'normal', 3: 'in', 4: 'out'}\n"
     ]
    }
   ],
   "source": [
    "encoding_to_label = {v: k for k, v in LABEL_ENCODING.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dd9066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score: 0.681\n",
      "f1 score : 0.3531721582130049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       0.47      0.58      0.52      1415\n",
      "       noise       0.55      0.29      0.38      1011\n",
      "      normal       0.78      0.97      0.86      3578\n",
      "          in       0.00      0.00      0.00       369\n",
      "         out       0.00      0.00      0.00       347\n",
      "\n",
      "    accuracy                           0.68      6720\n",
      "   macro avg       0.36      0.37      0.35      6720\n",
      "weighted avg       0.60      0.68      0.63      6720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/botu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/botu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/botu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, multilabel_confusion_matrix, plot_roc_curve\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(test_y, pred_y)\n",
    "print(f'Mean accuracy score: {accuracy:.3}')\n",
    "\n",
    "labels = [key for key in LABEL_ENCODING.keys()]\n",
    "\n",
    "f1 = f1_score(test_y, pred_y, average='macro')\n",
    "print('f1 score :', f1)\n",
    "\n",
    "print(classification_report(test_y, pred_y, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bfe3e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4367,  938],\n",
       "        [ 588,  827]],\n",
       "\n",
       "       [[5470,  239],\n",
       "        [ 716,  295]],\n",
       "\n",
       "       [[2176,  966],\n",
       "        [ 123, 3455]],\n",
       "\n",
       "       [[6351,    0],\n",
       "        [ 369,    0]],\n",
       "\n",
       "       [[6373,    0],\n",
       "        [ 347,    0]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee310814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
